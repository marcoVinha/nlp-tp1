{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING, format=\"%(asctime)s %(message)s\", datefmt=date_strftime_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "- Source: http://mattmahoney.net/dc/text8.zip\n",
    "- Stored in: `data/train.txt`\n",
    "\n",
    "### Analogies data\n",
    "- Source: https://raw.githubusercontent.com/nicholas-leonard/word2vec/refs/heads/master/questions-words.txt\n",
    "- Stored in: `data/analogies.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.word2vec import Text8Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreLossCurveCallback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.last_logged_loss = 0\n",
    "        self.loss_curve = []\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        curr_loss = model.get_latest_training_loss() - self.last_logged_loss\n",
    "        self.last_logged_loss = model.get_latest_training_loss()\n",
    "\n",
    "        self.loss_curve.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f\"Loss for epoch #{self.epoch}: {curr_loss}\"\n",
    "        )\n",
    "\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str,\n",
    "        window_size: int,\n",
    "        embedding_size: int,\n",
    "        min_word_count: int = 0,\n",
    "    ):\n",
    "        self.model_type = model_type\n",
    "        self._sg = 1 if model_type ==  \"skipgram\" else 0\n",
    "        self.window_size = window_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.min_word_count = min_word_count\n",
    "        self.compute_loss = True\n",
    "\n",
    "        self._loss_container = StoreLossCurveCallback()\n",
    "        self.loss_curve = []\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        training_corpus_fpath: str,\n",
    "        epochs: int,\n",
    "        workers: int = 8,\n",
    "    ):\n",
    "        self.model = Word2Vec(\n",
    "            sentences=Text8Corpus(fname=training_corpus_fpath),\n",
    "            sg=self._sg,\n",
    "            window=self.window_size,\n",
    "            vector_size=self.embedding_size,\n",
    "            epochs=epochs,\n",
    "            min_count=self.min_word_count,\n",
    "            compute_loss=self.compute_loss,\n",
    "            callbacks=[self._loss_container],\n",
    "            workers=workers,\n",
    "        )\n",
    "\n",
    "        self.loss_curve = self._loss_container.loss_curve\n",
    "\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        test_analogies_fpath: str,\n",
    "        return_test_sections: bool = True,\n",
    "    ):\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model not trained. Call `self.train` before calculating score.\")\n",
    "\n",
    "        score, sections = self.model.wv.evaluate_word_analogies(\n",
    "            test_analogies_fpath,\n",
    "        )\n",
    "\n",
    "        if return_test_sections: return score, sections\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching best hyper-parameters configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(\n",
    "    param_grid: dict,\n",
    "    param_conditions_callback: callable = None,\n",
    "    return_best: bool = False\n",
    "):\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "    param_keys = list(param_grid.keys())\n",
    "\n",
    "    results = []\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_keys, params))\n",
    "\n",
    "        if not param_conditions_callback(param_dict):\n",
    "            continue\n",
    "\n",
    "        model = Word2VecModel(\n",
    "            model_type=param_dict[\"model_type\"],\n",
    "            window_size=param_dict[\"window_size\"],\n",
    "            embedding_size=param_dict[\"embedding_size\"],\n",
    "        )\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "        model.train(\n",
    "            training_corpus_fpath=\"../data/train.txt\",\n",
    "            epochs=param_dict[\"epochs\"],\n",
    "        )\n",
    "\n",
    "        score = model.score(\n",
    "            test_analogies_fpath=\"../data/analogies.txt\",\n",
    "            return_test_sections=False,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"model_type: {model.model_type}, window_size: {model.window_size}, embedding_size: {model.embedding_size}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Final score: {score}\\n\"\n",
    "        )\n",
    "\n",
    "        results.append({\"params\": param_dict, \"score\": score})\n",
    "\n",
    "    if not return_best:\n",
    "        return results\n",
    "\n",
    "    return max(results, key=lambda x: x[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_param_combination(selected_params: dict):\n",
    "    return (\n",
    "        selected_params[\"window_size\"]\n",
    "        <= selected_params[\"epochs\"]\n",
    "        <= selected_params[\"embedding_size\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"model_type\": [\"skipgram\", \"cbow\"],\n",
    "    \"embedding_size\": [5, 10, 15],\n",
    "    \"window_size\": [3, 5],\n",
    "    \"epochs\": [5, 10],\n",
    "}\n",
    "\n",
    "grid_search_results = run_grid_search(\n",
    "    param_grid=param_grid,\n",
    "    param_conditions_callback=is_valid_param_combination,\n",
    "    return_best=True\n",
    ")\n",
    "\n",
    "grid_search_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
